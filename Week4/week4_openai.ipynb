{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlb5BXMRdF1synLFFP1VoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jun0S2/AIBootcamp/blob/main/week4_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9dmoNWBcjGe",
        "outputId": "b98b6a0e-3569-44b8-8373-76a2161ac6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.59.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install pandas numpy json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # 계속 1.xxx 버전에서 오류가 나서 다운그레이드 함\n",
        "!pip install openai==0.28.0# 계속 1.xxx 버전에서 오류가 나서 다운그레이드 함\n",
        "!pip show openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMnrYU-ngZ6F",
        "outputId": "06a3267d-ac9a-452d-846e-edc5651895c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 0.28.0\n",
            "Summary: Python client library for the OpenAI API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: OpenAI\n",
            "Author-email: support@openai.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, requests, tqdm\n",
            "Required-by: \n",
            "Requirement already satisfied: openai==0.28.0 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28.0) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "api & json load\n",
        "\n",
        "https://platform.openai.com/api-keys 에서 secret key 발급\n"
      ],
      "metadata": {
        "id": "yorLnWovcuah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# .env 파일 로드\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "I5FZfOo_u_zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "import numpy as np\n",
        "import asyncio\n",
        "\n",
        "# GPT-4 API Key 설정\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "try:\n",
        "    models = openai.Model.list()\n",
        "    print(\"Available models:\")\n",
        "    for model in models[\"data\"]:\n",
        "        print(model[\"id\"])\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving models: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-TX1sqycxk5",
        "outputId": "a547c9cd-1fc4-4087-bfa1-b056237d4dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models:\n",
            "dall-e-2\n",
            "gpt-3.5-turbo\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-3.5-turbo-instruct\n",
            "babbage-002\n",
            "whisper-1\n",
            "dall-e-3\n",
            "gpt-3.5-turbo-16k\n",
            "omni-moderation-latest\n",
            "o1-preview-2024-09-12\n",
            "omni-moderation-2024-09-26\n",
            "tts-1-hd-1106\n",
            "o1-preview\n",
            "tts-1-hd\n",
            "davinci-002\n",
            "text-embedding-ada-002\n",
            "gpt-3.5-turbo-1106\n",
            "tts-1\n",
            "tts-1-1106\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "text-embedding-3-small\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini\n",
            "text-embedding-3-large\n",
            "o1-mini\n",
            "o1-mini-2024-09-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt 4o 는 리스트에 없어서 4o-mini 로 하였는데 뭔가 잘못한건가요.."
      ],
      "metadata": {
        "id": "z-VGgvDplt0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FlDJ-szUl3lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# api test\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"나의 프롬프트 엔지니어링 코치가 되어줘.\"},\n",
        "        {\"role\": \"user\", \"content\": \"어떻게 하면 프롬프트 엔지니어링을 잘 할수 있을까?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Assistant: \" + response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "sr-zOxk-l38A",
        "outputId": "c1afab6c-2aac-4b01-d1d3-95ca872e6948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c2a9167846a8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# api test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 데이터 로드 함수\n",
        "def load_kice_data(filepath):\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        return json.load(file)"
      ],
      "metadata": {
        "id": "oJNIQpLyk6g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "json -> GPT4 로 예측"
      ],
      "metadata": {
        "id": "Lhl4CtHpc7Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제 예측 함수\n",
        "def prediction(problem):\n",
        "    \"\"\"\n",
        "    문제(json 형태)를 받아 GPT-4가 예측한 정답을 반환합니다.\n",
        "    \"\"\"\n",
        "    # 문제 구성\n",
        "    prompt = f\"다음은 수능 국어 문제입니다:\\n\\n질문: {problem['question']}\\n\\n선택지:\\n\"\n",
        "    for idx, choice in enumerate(problem['choices'], start=1):\n",
        "        prompt += f\"{idx}. {choice}\\n\"\n",
        "\n",
        "    prompt += \"\\n정답을 선택지 번호로 답하세요.\"\n",
        "\n",
        "    try:\n",
        "        # GPT-4 API 호출\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"당신은 수능 국어 전문가입니다.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # 응답에서 정답 추출\n",
        "        gpt_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        answer = int(gpt_response.strip())\n",
        "        return answer\n",
        "    except ValueError:\n",
        "        print(f\"Invalid response: {gpt_response}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"API 호출 오류: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "-4ObGrmkc3-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "점수 계산"
      ],
      "metadata": {
        "id": "2nEO8gmcdHCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_score(predictions, answers):\n",
        "    \"\"\"\n",
        "    GPT-4 예측 결과와 실제 정답을 비교하여 점수를 계산합니다.\n",
        "    \"\"\"\n",
        "    correct = sum([1 for pred, answer in zip(predictions, answers) if pred == answer])\n",
        "    total = len(answers)\n",
        "    return (correct / total) * 100"
      ],
      "metadata": {
        "id": "3XpF1mvYdIJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 로드"
      ],
      "metadata": {
        "id": "stkunmgmdKLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드\n",
        "print(\"Loading KICE data...\")\n",
        "# GitHub에서 데이터 다운로드\n",
        "!git clone https://github.com/NomaDamas/KICE_slayer_AI_Korean.git\n",
        "\n",
        "# JSON 데이터 로드\n",
        "data = load_kice_data(\"KICE_slayer_AI_Korean/data/2023_11_KICE.json\")\n",
        "print(\"KICE data loaded successfully.\")\n",
        "\n",
        "# 데이터 타입 확인\n",
        "print(type(data))  # 데이터 타입 확인 -> 리스트임\n",
        "print(data[:5])    # 데이터의 첫 5개 항목 확인 (리스트인 경우)\n",
        "\n",
        "# 문제와 정답 리스트 생성\n",
        "problems = []\n",
        "answers = []\n",
        "\n",
        "# 데이터에서 문제와 정답을 추출\n",
        "for item in data:\n",
        "    for problem in item['problems']:\n",
        "        problems.append(problem)\n",
        "        answers.append(problem['answer'])  # 실제 정답 추가\n",
        "\n",
        "print(f\"Number of problems loaded: {len(problems)}\")\n",
        "# print(f\"First problem: {problems[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-BVOEYMdLrt",
        "outputId": "fe6954f1-0e66-4c90-e84a-e0789871e30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading KICE data...\n",
            "fatal: destination path 'KICE_slayer_AI_Korean' already exists and is not an empty directory.\n",
            "KICE data loaded successfully.\n",
            "<class 'list'>\n",
            "[{'id': '2023_11_KICE_1-3', 'paragraph': '사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 가지가 있겠지만 그 중심에는 ‘소통의 즐거움’이 있다.독자는 독서를 통해 책과 소통하는 즐거움을 경험한다. 독서는필자와 간접적으로 대화하는 소통 행위이다. 독자는 자신이 속한사회나 시대의 영향 아래 필자가 속해 있거나 드러내고자 하는 사회나 시대를 경험한다. 직접 경험하지 못했던 다양한 삶을 필자를 매개로 만나고 이해하면서 독자는 더 넓은 시야로 세계를바라볼 수 있다. 이때 같은 책을 읽은 독자라도 독자의 배경지식이나 관점 등의 독자 요인, 읽기 환경이나 과제 등의 상황 요인이 다르므로, 필자가 보여 주는 세계를 그대로 수용하지 않고 저마다 소통 과정에서 다른 의미를 구성할 수 있다.[A] (이러한 소통은 독자가 책의 내용에 대해 질문하고 답을 찾아내는 과정에서 가능해진다. 독자는 책에서 답을 찾는 질문, 독자 자신에게서 답을 찾는 질문 등을 제기할 수 있다. 전자의 경우 책에 명시된 내용에서 답을 발견할 수 있고, 책의 내용들을 관계 지으며 답에 해당하는 내용을 스스로 구성할 수도 있다. 또한 후자의 경우 책에는 없는 독자의 경험에서 답을 찾을 수 있다. 이런 질문들을 풍부히 생성하고 주체적으로 답을 찾을 때 소통의 즐거움은 더 커진다.)한편 독자는 ㉠ (다른 독자와 소통하는 즐거움을 경험할 수도 있다.) 책과의 소통을 통해 개인적으로 형성한 의미를 독서 모임이나 독서 동아리 등에서 다른 독자들과 나누는 일이 이에 해당한다. 비슷한 해석에 서로 공감하며 기존 인식을 강화하거나 관점의 차이를 확인하고 기존 인식을 조정하는 과정에서, 독자는자신의 인식을 심화 확장할 수 있다. 최근 소통 공간이 온라인으로 확대되면서 독서를 통해 다른 독자들과 소통하며 즐거움을누리는 양상이 더 다양해지고 있다. 자신의 독서 경험을 담은 글이나 동영상을 생산 공유함으로써, 책을 읽지 않은 타인이 책과 소통하도록 돕는 것도 책을 통한 소통의 즐거움을 나누는 일이다.', 'type': 0, 'problems': [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices': ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.', '독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다'], 'answer': 4, 'score': 2}, {'question': '다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?', 'question_plus': \"ⓐ('음악 시간에 들었던 베토벤의 교향곡 <합창>이 위대한 작품인 이유는 무엇일까?'하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) <합창>을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.\", 'choices': ['ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.', 'ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.', 'ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.', 'ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.', 'ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.'], 'answer': 5, 'score': 3}, {'question': '윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?', 'choices': ['스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.', '독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.', '개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.', '자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.', '오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.'], 'answer': 1, 'score': 2}]}, {'id': '2023_11_KICE_4-9', 'paragraph': '(가)[A](중국에서 비롯된 유서(類書)는 고금의 서적에서 자료를 수집하고 항목별로 분류, 정리하여 이용에 편리하도록 편찬한서적이다. 일반적으로 유서는 기존 서적에서 필요한 부분을뽑아 배열할 뿐 상호 비교하거나 편찬자의 해석을 가하지 않았다. 유서는 모든 주제를 망라한 일반 유서와 특정 주제를다룬 전문 유서로 나눌 수 있으며, 편찬 방식은 책에 따라다른 경우가 많았다. 중국에서는 대체로 왕조 초기에 많은 학자를 동원하여 국가 주도로 대규모 유서를 편찬하여 간행하였다. 이를 통해 이전까지의 지식을 집성하고 왕조의 위엄을 과시할 수 있었다.고려 때 중국 유서를 수용한 이후, 조선에서는 중국 유서를활용하는 한편, 중국 유서의 편찬 방식에 ⓐ(따라) 필요에 맞게 유서를 편찬하였다. 조선의 유서는 대체로 국가보다 개인이 소규모로 편찬하는 경우가 많았고, 목적에 따른 특정주제의 전문 유서가 집중적으로 편찬되었다. 전문 유서 가운데 편찬자가 미상인 유서가 많은데, 대체로 간행을 염두에 두지 않고 기존 서적에서 필요한 부분을 발췌, 기록하여 시문 창작, 과거 시험 등 개인적 목적으로 유서를 활용하고자 하였기 때문이었다.)이 같은 유서 편찬 경향이 지속되는 가운데 17세기부터 실학의학풍이 하나의 조류를 형성하면서 유서 편찬에 변화가 나타났다. ㉮(실학자들의 유서)는 현실 개혁의 뜻을 담았고, 편찬 의도를 지식의 제공과 확산에 두었다. 또한 단순 정리를 넘어 지식을 재분류하여 범주화하고 평가를 더하는 등 저술의 성격을 드러냈다. 독서와 견문을 통해 주자학에서 중시되지 않았던 지식을 집적했고, 증거를 세워 이론적으로 밝히는 고증과 이에 대한 의견 등 ‘안설’을 덧붙이는 경우가 많았다. 주자학의 지식을 ⓑ(이어받는) 한편, 주자학이 아닌 새로운 지식을 수용하는 유연성과 개방성을 보였다. 광범위하게 정리한 지식을 식자층이 ⓒ(쉽게) 접할 수 있어야 한다고 생각했고, 객관적 사실 탐구를 중시하여 박물학과 자연 과학에 관심을 기울였다.조선 후기 실학자들이 편찬한 유서가 주자학의 관념적 사유에 국한되지 않고 새로운 지식의 축적과 확산을 촉진한 것은 지식의역사에서 적지 않은 의미를 지닌다.(나)예수회 선교사들이 중국에 소개한 서양의 학문, 곧 서학은 조선 후기 유서(類書)의 지적 자원 중 하나로 활용되었다. 조선 후기 실학자들 가운데 이수광, 이익, 이규경 등이 편찬한 백과전서식 유서는 주자학의 지적 영역 내에서 서학의 지식을 어떻게수용하였는지를 보여 주는 대표적인 사례이다.17세기의 이수광은 주자학뿐 아니라 다른 학문에 대해서도 열린 태도를 가지고 있었다. 주자학에 기초하여 도덕에 관한 학문과 경전에 관한 학문 등이 주류였던 당시 상황에서, 그는 지봉유설을 통해 당대 조선의 지식을 망라하여 항목화하고 자신의 견해를 덧붙였을 뿐 아니라 사신의 일원으로 중국에서 접한 서양 관련 지식을 객관적으로 소개했다. 이에 대해 심성 수양에 절실하지 않을뿐더러 주자학이 아닌 것이 ⓓ(뒤섞여) 순수하지 않다는 ㉯(일부 주자학자의 비판)이 있었지만, 그가 소개한 서양 관련 지식은 중국과 큰 시간 차이 없이 주변에 알려졌다.18세기의 이익은 서학 지식 자체를 ㉠(성호사설)의 표제어로삼았고, 기존의 학설을 정당화하거나 배제하는 근거로 서학을 수용하는 등 서학을 지적 자원으로 활용하였다. 특히 그는 서학의 세부 내용을 다른 분야로 확대하며 상호 참조하는 방식으로 지식을 심화하고 확장하여 소개하였다. 서학의 해부학과 생리학을 그 자체로 수용하지 않고 주자학 심성론의 하위 이론으로 재분류하는 등 지식의 범주를 ⓔ(바꾸어) 수용하였다. 또한 서학의 수학을 주자학의 지식 영역 안에서 재구성하기도 하였다.19세기의 이규경도 ㉡(오주연문장전산고)를 편찬하면서 서학을 적극 활용하였다. 그는 성호사설의 분류 체계를 적용하였고 이익과 마찬가지로 서학의 천문학, 우주론 등의 내용을 수록하였다. 그가 주로 유서의 지적 자원으로 활용한 중국의 서학 연구서들은 서학을 소화하여 중국의 학문과 절충한 것이었고, 서학이 가지는 진보성의 토대가 중국이라는 서학 중국 원류설을 반영한 것이었다. 이에 따라 이규경은 이 책들에 담긴 중국화한 서학 지식과 서학 중국 원류설을 받아들였고, 문명의 척도로 여겨진 기존의 중화 관념에서 탈피하지 않으면서도 서학 수용의 이질감과 부담감에서 자유로울 수 있었다. 이렇듯 이규경은 중국의 서학 연구서들을 활용해 매개적 방식으로 서학을 수용하였다.', 'type': 0, 'problems': [{'question': '(가)와 (나)에 대한 설명으로 가장 적절한 것은?', 'choices': ['(가)는 유서의 유형을 분류하였고, (나)는 유서의 분류 기준과적절성 여부를 평가하였다.', '(가)는 유서의 개념과 유용성을 소개하였고, (나)는 국가별 유서의 변천 과정을 설명하였다.', '(가)는 유서의 기원에 대한 다양한 학설을 검토하였고, (나)는 유서 편찬자들 간의 견해 차이를 분석하였다.', '(가)는 유서의 특성과 의의를 설명하였고, (나)는 유서 편찬에서 특정 학문의 수용 양상을 시기별로 소개하였다.', '(가)는 유서에 대한 평가가 시대별로 달라진 원인을 분석하였고, (나)는 역사적으로 대표적인 유서의 특징을 제시하였다.'], 'answer': 4, 'score': 2}, {'question': '[A]에 대한 이해로 적절하지 않은 것은?', 'choices': ['조선에서 편찬자가 미상인 유서가 많았던 것은 편찬자의 개인적 목적으로 유서를 활용하려 했기 때문이다.', '조선에서는 시문 창작, 과거 시험 등에 필요한 내용을 담은 유서가 편찬되는 경우가 적지 않았다.', '조선에서는 중국의 편찬 방식을 따르면서도 대체로 국가보다는개인에 의해 유서가 편찬되었다.', '중국에서는 많은 학자를 동원하여 대규모로 편찬한 유서를 통해 왕조의 위엄을 드러내었다.', '중국에서는 주로 서적에서 발췌한 내용을 비교하고 해석을 덧붙여 유서를 편찬하였다.'], 'answer': 5, 'score': 2}, {'question': '㉮에 대한 이해를 바탕으로 ㉠, ㉡에 대해 파악한 내용으로 적절하지 않은 것은?', 'choices': ['지식의 제공이라는 ㉮의 편찬 의도는, ㉠에서 지식을 심화하고확장하여 소개한 것에서 나타난다.', '지식을 재분류하여 범주화한 ㉮의 방식은, ㉠에서 해부학과 생리학을 주자학 심성론의 하위 이론으로 수용한 것에서 나타난다.', '평가를 더하는 저술로서 ㉮의 성격은, ㉡에서 중국 학문의 진보성을 확인하고자 서학을 활용한 것에서 나타난다.', '사실 탐구를 중시하며 자연 과학에 대해 드러낸 ㉮의 관심은, ㉡에서 천문학과 우주론의 내용을 수록한 것에서 나타난다.', '새로운 지식을 수용하는 ㉮의 유연성과 개방성은, ㉠과 ㉡에서서학을 지적 자원으로 받아들인 것에서 나타난다.'], 'answer': 3, 'score': 2}, {'question': '㉯를 반박하기 위한 ‘이수광’의 말로 가장 적절한 것은?', 'choices': ['학문에서 의리를 앞세우고 이익을 뒤로하는 것보다 중한 것이없으니, 심성을 수양하는 것은 그다음의 일이다.', '주자학에 매몰되어 세상의 여러 이치를 연구하지 않는 것은 널리 배우고 익히는 앎의 바른 방법이 아닐 것이다.', '주자의 가르침이 쇠퇴하게 되면 주자학이 아닌 학문이 날로 번성하게 되니, 주자의 도가 분명히 밝혀져야 한다.', '유학 경전에서 쓰이지 않은 글자를 한 글자라도 더하는 일을 용납하는 것은 바른 학문을 해치는 길이 될 것이다.', '참되게 알고 참되게 행하는 것이 어려우니, 우리 학문의 여러경전으로부터 널리 배우고 면밀히 익혀야 할 것이다.'], 'answer': 2, 'score': 2}, {'question': '(가), (나)를 읽은 학생이 <보기>의 임원경제지에 대해 보인 반응으로 적절하지 않은 것은?', 'question_plus': '<보기> 서유구의 임원경제지는 19세기까지의 조선과 중국 서적들에서 향촌 관련 부분을 발췌, 분류하고 고증한 유서이다. 국가를 위한다는 목적의식을 명시한 이 유서에는 향촌 사대부의 이상적인 삶을 제시하는 과정에서 향촌 구성원 전체의 삶의 조건을 개선할 수 있는 방안이 실렸고, 향촌 실생활에서활용할 수 있는 내용이 집성되었다. 주자학을 기반으로 실증과실용의 자세를 견지했던 서유구의 입장, 서학 중국 원류설, 중국과 비교한 조선의 현실 등이 반영되었다. 안설을 부기했으며, 제한적으로 색인을 넣어 검색이 가능하도록 하였다.', 'choices': ['현실 개혁의 뜻을 담았던 (가)의 실학자들의 유서와 마찬가지로 현실의 문제를 개선하려는 목적의식이 확인되겠군.', '증거를 제시하여 이론적으로 밝히거나 의견을 제시하는 경우가많았던 (가)의 실학자들의 유서와 마찬가지로 편찬자의 고증과의견이 반영된 것이 확인되겠군.', '당대 지식을 망라하고 서양 관련 지식을 소개하고자 한 (나)의 지봉유설에 비해 특정한 주제를 중심으로 편찬되는 전문 유서의 성격이 두드러지게 드러나겠군.', '기존 학설의 정당화 내지 배제에 관심을 두었던 (나)의 성호사설에 비해 향촌 사회 구성원의 삶에 필요한 실용적인 지식의활용에 대한 관심이 드러나겠군.', '중국을 문명의 척도로 받아들였던 (나)의 오주연문장전산고와 달리 중화 관념에 구애되지 않고 중국의 현실과 조선의 현실을 비교한 내용이 확인되겠군.'], 'answer': 5, 'score': 3}, {'question': '문맥상 ⓐ～ⓔ와 바꾸어 쓰기에 적절하지 않은 것은?', 'choices': ['ⓐ : 의거(依據)하여', 'ⓑ : 계몽(啓蒙)하는', 'ⓒ : 용이(容易)하게', 'ⓓ : 혼재(混在)되어', 'ⓔ : 변경(變更)하여'], 'answer': 2, 'score': 2}]}, {'id': '2023_11_KICE_10-13', 'paragraph': '법령의 조문은 대개 ‘A에 해당하면 B를 해야 한다.’처럼 요건과효과로 구성된 조건문으로 규정된다. 하지만 그 요건이나 효과가항상 일의적인 것은 아니다. 법조문에는 구체적 상황을 고려해야그 상황에 ⓐ(맞는) 진정한 의미가 파악되는 불확정 개념이 사용될 수 있기 때문이다. 개인 간 법률관계를 규율하는 민법에서 불확정 개념이 사용된 예로 ‘손해 배상 예정액이 부당히 과다한경우에는 법원은 적당히 감액할 수 있다.’라는 조문을 ⓑ(들) 수 있다. 이때 법원은 요건과 효과를 재량으로 판단할 수 있다. 손해배상 예정액은 위약금의 일종이며, 계약 위반에 대한 제재인 위약벌도 위약금에 속한다. 위약금의 성격이 둘 중 무엇인지 증명되지 못하면 손해 배상 예정액으로 다루어진다.채무자의 잘못으로 계약 내용이 실현되지 못하여 계약 위반이발생하면, 이로 인해 손해를 입은 채권자가 손해 액수를 증명해야 그 액수만큼 손해 배상금을 받을 수 있다. 그러나 손해 배상 예정액이 정해져 있었다면 채권자는 손해 액수를 증명하지 않아도 손해 배상 예정액만큼 손해 배상금을 받을 수 있다. 이때 손해 액수가 얼마로 증명되든 손해 배상 예정액보다 더 받을 수는 없다. 한편 위약금이 위약벌임이 증명되면 채권자는 위약벌에 해당하는 위약금을 ⓒ(받을) 수 있고, 손해 배상 예정액과는 달리 법원이 감액할 수 없다. 이때 채권자가 손해 액수를증명하면 손해 배상금도 받을 수 있다.불확정 개념은 행정 법령에도 사용된다. 행정 법령은 행정청이구체적 사실에 대해 행하는 법 집행인 행정 작용을 규율한다. 법령상 요건이 충족되면 그 효과로서 행정청이 반드시 해야 하는특정 내용의 행정 작용은 기속 행위이다. 반면 법령상 요건이 충족되더라도 그 효과인 행정 작용의 구체적 내용을 ⓓ(고를)수 있는 재량이 행정청에 주어져 있을 때, 이러한 재량을 행사하는 행정 작용은 재량 행위이다. 법령에서 불확정 개념이 사용되면 이에 근거한 행정 작용은 대개 재량 행위이다.행정청은 재량으로 재량 행사의 기준을 명확히 정할 수 있는데 이 기준을 ㉠(재량 준칙)이라 한다. 재량 준칙은 법령이 아니므로 재량 준칙대로 재량을 행사하지 않아도 근거 법령 위반은 아니다. 다만 특정 요건하에 재량 준칙대로 특정한 내용의 적법한 행정 작용이 반복되어 행정 관행이 생긴 후에는, 같은 요건이 충족되면 행정청은 동일한 내용의 행정 작용을 해야 한다. 행정청은 평등 원칙을 ⓔ(지켜야) 하기 때문이다.', 'type': 0, 'problems': [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices': ['법령의 요건과 효과에는 모두 불확정 개념이 사용될 수 있다.', '법원은 불확정 개념이 사용된 법령을 적용할 때 재량을 행사할 수 있다.', '불확정 개념이 사용된 법령의 진정한 의미를 이해하려면 구체적 상황을 고려해야 한다.', '불확정 개념이 사용된 행정 법령에 근거한 행정 작용은 재량 행위인 경우보다 기속 행위인 경우가 많다.', '불확정 개념은 행정청이 행하는 법 집행 작용을 규율하는 법령과 개인 간의 계약 관계를 규율하는 법률에 모두 사용된다.'], 'answer': 4, 'score': 2}, {'question': '㉠에 대한 이해로 가장 적절한 것은?', 'choices': ['재량 준칙은 법령이 아니기 때문에 일의적이지 않은 개념으로 규정된다.', '재량 준칙으로 정해진 내용대로 재량을 행사하는 행정 작용은 기속 행위이다.', '재량 준칙으로 규정된 재량 행사 기준은 반복되어 온 적법한 행정 작용의 내용대로 정해져야 한다.', '재량 준칙이 정해져야 행정청은 특정 요건하에 행정 작용의 구체적 내용을 선택할 수 있는 재량을 행사할 수 있다.', '재량 준칙이 특정 요건에서 적용된 선례가 없으면 행정청은 동일한 요건이 충족되어도 행정 작용을 할 때 재량 준칙을 따르지 않을 수 있다.'], 'answer': 5, 'score': 2}, {'question': '윗글을 바탕으로 <보기>를 이해한 내용으로 가장 적절한 것은? [3점]', 'question_plus': '<보 기> 갑은 을에게 물건을 팔고 그 대가로 100을 받기로 하는 매매 계약을 했다. 그 후 갑이 계약을 위반하여 을은 80의 손해를 입었다. 이와 관련하여 세 가지 상황이 있다고 하자. (가)(갑과 을 사이에 위약금 약정이 없었다.) (나)(갑이 을에게 위약금 100을 약정했고, 위약금의 성격이 무엇인지 증명되지 못했다.) (다)(갑이 을에게 위약금 100을 약정했고, 위약금의 성격이 위약벌임이 증명되었다.) 단, 위의 모든 상황에서 세금, 이자 및 기타 비용은 고려하지 않음.', 'choices': ['(가)에서 을의 손해가 얼마인지 증명되지 못한 경우에도, 갑이을에게 80을 지급해야 하고 법원이 감액할 수 없다.', '(나)에서 을의 손해가 80임이 증명된 경우, 갑이 을에게 100을지급해야 하고 법원이 감액할 수 있다.', '(나)에서 을의 손해가 얼마인지 증명되지 못한 경우, 갑이 을에게 100을 지급해야 하고 법원이 감액할 수 없다', '(다)에서 을의 손해가 80임이 증명된 경우, 갑이 을에게 180을지급해야 하고 법원이 감액할 수 있다.', '(다)에서 을의 손해가 얼마인지 증명되지 못한 경우, 갑이 을에게 80을 지급해야 하고 법원이 감액할 수 없다.'], 'answer': 2, 'score': 3}, {'question': '문맥상 ⓐ～ⓔ의 의미와 가장 가까운 것은?', 'choices': ['이것이 네가 찾는 자료가 ⓐ(맞는지) 확인해 보아라.', '그 부부는 노후 대책으로 적금을 ⓑ(들고) 안심했다.', '그의 파격적인 주장은 학계의 큰 주목을 ⓒ(받았다).', '형은 땀 흘려 울퉁불퉁한 땅을 평평하게 ⓓ(골랐다).', '그분은 우리에게 한 약속을 반드시 ⓔ(지킬) 것이다.'], 'answer': 5, 'score': 2, 'type': 3}]}, {'id': '2023_11_KICE_14-17', 'paragraph': '하루에 필요한 에너지의 양은 하루 동안의 총 열량 소모량인 대사량으로 구한다. 그중 기초 대사량은 생존에 필수적인 에너지로, 쾌적한 온도에서 편히 쉬는 동물이 공복 상태에서 생성하는열량으로 정의된다. 이때 체내에서 생성한 열량은 일정한 체온에서 체외로 발산되는 열량과 같다. 기초 대사량은 개체에 따라대사량의 60～75%를 차지하고, 근육량이 많을수록 증가한다.기초 대사량은 직접법 또는 간접법으로 구한다. ㉠ (직접법)은 온도가 일정하게 유지되고 공기의 출입량을 알고 있는 호흡실에서 동물이 발산하는 열량을 열량계를 이용해 측정하는 방법이다. ㉡ (간접법)은 호흡 측정 장치를 이용해 동물의 산소 소비량과 이산화 탄소 배출량을 측정하고, 이를 기준으로 체내에서 생성된 열량을 추정하는 방법이다.19세기의 초기 연구는 체외로 발산되는 열량이 체표 면적에 비례한다고 보았다. 즉 그 둘이 항상 일정한 비(比)를 갖는다는 것이다. 체표 면적은 (체중)^0.67에 비례하므로, 기초 대사량은 체중이 아닌 (체중)^0.67에 비례한다고 하였다. 어떤 변수의 증가율은 증가 후 값을 증가 전 값으로 나눈 값이므로, 체중이 W에서2W로 커지면 체중의 증가율은 (2W) / (W)＝2이다. 이 경우에 기초대사량의 증가율은 (2W)^0.67 / (W)^0.67 ＝ 2^0.67, 즉 약 1.6이 된다.1930년대에 클라이버는 생쥐부터 코끼리까지 다양한 크기의 동물의 기초 대사량 측정 결과를 분석했다. 그래프의 가로축 변수로 동물의 체중을, 세로축 변수로 기초 대사량을 두고, 각 동물별 체중과 기초 대사량의 순서쌍을 점으로 나타냈다. 가로축과 세로축 두 변수의 증가율이 서로 다를 경우, 그 둘의 증가율이 같을 때와 달리, ‘일반적인 그래프’에서 이 점들은 직선이 아닌 어떤 곡선의 주변에 분포한다. 그런데 순서쌍의 값에 상용로그를 취해 새로운 순서쌍을 만들어서 이를 <그림>과같이 그래프에 표시하면, 어떤 직선의 주변에 점들이 분포하는 것으로 나타난다. 그러면 그 직선의 기울기를 이용해두 변수의 증가율을 비교할 수 있다. <그림>에서 X와 Y는 각각 체중과 기초대사량에 상용로그를 취한 값이다. 이런 방식으로 표현한 그래프를 ‘L-그래프’라 하자. 체중의 증가율에 비해, 기초 대사량의 증가율이 작다면 L-그래프에서 직선의 기울기는 1보다 작으며 기초 대사량의 증가율이 작을수록 기울기도 작아진다. 만약 체중의 증가율과 기초 대사량의 증가율이 같다면 L-그래프에서 직선의 기울기는 1이 된다.이렇듯 L-그래프와 같은 방식으로 표현할 때, 생물의 어떤 형질이 체중 또는 몸 크기와 직선의 관계를 보이며 함께 증가하는 경우 그 형질은 ‘상대 성장’을 한다고 한다. 동일 종에서의심장, 두뇌와 같은 신체 기관의 크기도 상대 성장을 따른다.한편, 그래프에서 가로축과 세로축 두 변수의 관계를 대변하는최적의 직선의 기울기와 절편은 최소 제곱법으로 구할 수 있다. 우선, 그래프에 두 변수의 순서쌍을 나타낸 점들 사이를 지나는임의의 직선을 그린다. 각 점에서 가로축에 수직 방향으로 직선까지의 거리인 편차의 절댓값을 구하고 이들을 각각 제곱하여 모두 합한 것이 ‘편차 제곱 합’이며, 편차 제곱 합이 가장 작은 직선을 구하는 것이 최소 제곱법이다.클라이버는 이런 방법에 근거하여 L-그래프에 나타난 최적의직선의 기울기로 0.75를 얻었고, 이에 따라 동물의 (체중)^0.75에 기초 대사량이 비례한다고 결론지었다. 이것을 ‘클라이버의 법칙’이라 하며, (체중)^0.75을 대사 체중이라 부른다. 대사 체중은 치료제 허용량의 결정에도 이용되는데, 이때 그 양은 대사 체중에 비례하여 정한다. 이는 치료제 허용량이 체내 대사와 밀접한 관련이 있기 때문이다.', 'type': 0, 'problems': [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices': ['클라이버의 법칙은 동물의 기초 대사량이 대사 체중에 비례한다고 본다.', '어떤 개체가 체중이 늘 때 다른 변화 없이 근육량이 늘면 기초 대사량이 증가한다.', '‘L-그래프’에서 직선의 기울기는 가로축과 세로축 두 변수의 증가율의 차이와 동일하다.', '최소 제곱법은 두 변수 간의 관계를 나타내는 최적의 직선의 기울기와 절편을 알게 해 준다.', '동물의 신체 기관인 심장과 두뇌의 크기는 몸무게나 몸의 크기에 상대 성장을 하며 발달한다.'], 'answer': 3, 'score': 2}, {'question': '윗글을 읽고 추론한 내용으로 적절하지 않은 것은?', 'choices': ['일반적인 경우 기초 대사량은 하루에 소모되는 총 열량 중에 가장 큰 비중을 차지하겠군.', '클라이버의 결론에 따르면, 기초 대사량이 동물의 체표 면적에 비례한다고 볼 수 없겠군.', '19세기의 초기 연구자들은 체중의 증가율보다 기초 대사량의 증가율이 작다고 생각했겠군.', '코끼리에게 적용하는 치료제 허용량을 기준으로, 체중에 비례하여 생쥐에게 적용할 허용량을 정한 후 먹이면 과다 복용이 될 수 있겠군.', '클라이버의 법칙에 따르면, 동물의 체중이 증가함에 따라 함께늘어나는 에너지의 필요량이 이전 초기 연구에서 생각했던 양보다 많겠군.'], 'answer': 4, 'score': 2}, {'question': '㉠, ㉡에 대한 이해로 가장 적절한 것은?', 'choices': ['㉠은 체온을 환경 온도에 따라 조정하는 변온 동물이 체외로 발산하는 열량을 측정할 수 없다.', '㉡은 동물이 호흡에 이용한 산소의 양을 알 필요가 없다.', '㉠은 ㉡과 달리 격한 움직임이 제한된 편하게 쉬는 상태에서 기초 대사량을 구한다.', '㉠과 ㉡은 모두 일정한 체온에서 동물이 체외로 발산하는 열량을 구할 수 있다.', '㉠과 ㉡은 모두 생존에 필수적인 최소한의 에너지를 공급하면서 기초 대사량을 구한다.'], 'answer': 4, 'score': 2}, {'question': '윗글을 바탕으로 <보기>를 탐구한 내용으로 가장 적절한 것은?', 'question_plus': \"<보기>농게의 수컷은 집게발 하나가매우 큰데, 큰 집게발의 길이는게딱지의 폭에 '상대 성장'을한다. 농게의 ⓐ(게딱지 폭)을이용해 ⓑ(큰 집게발의 길이)를 추정하기 위해, 다양한 크기의농게의 게딱지 폭과 큰 집게발의 길이를 측정하여 다수의순서쌍을 확보했다. 그리고 'L-그래프'와 같은 방식으로,그래프의 가로축과 세로축에 각각 게딱지 폭과 큰 집게발의길이에 해당하는 값을 놓고 분석을 실시했다.\", 'choices': ['최적의 직선을 구한다고 할 때, 최적의 직선의 기울기가 1보다 작다면 ⓐ에 ⓑ가 비례한다고 할 수 없겠군.', '최적의 직선을 구하여 ⓐ와 ⓑ의 증가율을 비교하려고 할 때, 점들이 최적의 직선으로부터 가로축에 수직 방향으로 멀리떨어질수록 편차 제곱 합은 더 작겠군.', 'ⓐ의 증가율보다 ⓑ의 증가율이 크다면, 점들의 분포가 직선이아닌 어떤 곡선의 주변에 분포하겠군.', 'ⓐ의 증가율보다 ⓑ의 증가율이 작다면, 점들 사이를 지나는 최적의 직선의 기울기는 1보다 크겠군.', 'ⓐ의 증가율과 ⓑ의 증가율이 같고 ‘일반적인 그래프’에서 순서쌍을 점으로 표시한다면, 점들은 직선이 아닌 어떤 곡선의주변에 분포하겠군.'], 'answer': 1, 'score': 3}]}, {'id': '2023_11_KICE_18-21', 'paragraph': '혼례를 마친 후 최척이 아내와 함께 장모를 모시고 집으로 돌아오매 하인들이 기뻐했다. 대청에 오르자 친척들이 축하하여온 집안에 기쁨이 넘쳤고, 이들을 기리는 소리가 사방의 이웃으로 퍼졌다. 시집에 온 옥영은 소매를 걷고 머리를 빗어 올린 채 손수 물을 긷고 절구질을 했으며, 시아버지를 봉양하고 남편을 대할 때 효와 정성을 다하고, 윗사람을 받들고 아랫사람을 대할 때는 성의와 예의를 두루 갖췄다. 이웃 사람들이 이를 듣고는 모두 양홍의 처나 포선의 아내도 이보다 낫지 않을것이라고 칭찬했다.최척은 결혼한 후 구하는 것이 뜻대로 되어 재산이 점차 넉넉히 불었으나, 다만 일찍이 자식이 없는 것이 걱정이었다. 최척 부부는 후사를 염려하여 ㉠(매월 초하루)가 되면 몸과 마음을 깨끗이 하고 함께 만복사에 올라 부처께 기도를 올렸다. 다음 해 갑오년 ㉡(정월 초하루)에도 만복사에 올라 기도를 했는데, 이날 밤 장육금불이 옥영의 꿈에 나타나 말했다.“나는 만복사의 부처로다. 너희 정성이 가상해 기이한 사내아이를 점지해 주니, 태어나면 반드시 특이한 징표가 있을 것이다.”옥영은 ㉢(그달)에 바로 잉태해 열 달 뒤 과연 아들을 낳았는데, 등에 어린아이 손바닥만 한 붉은 점이 있었다. 그래서 최척은 아들 이름을 몽석(夢釋)이라고 지었다.최척은 피리를 잘 불었으며, ㉣(매양 꽃 피는 아침과 달 뜬 밤)이되면 아내 곁에서 피리를 불곤 했다. 일찍이 날씨가 맑은 ㉤(어느 봄날 밤)이었는데, 어둠이 깊어 갈 무렵 미풍이 잠깐 일며 밝은 달이 환하게 비췄으며, 바람에 날리던 꽃잎이 옷에 떨어져 그윽한 향기가 코끝에 스며들었다. 이에 최척은 옥영과 술을 따라 마신 후, 침상에 기대 피리를 부니 그 여음이 하늘거리며 퍼져 나갔다. 옥영이 한동안 침묵하다 말했다.“저는 평소 여인이 시 읊는 것을 좋게 여기지 않습니다. 그런데이처럼 맑은 정경을 대하니 도저히 참을 수가 없군요.”옥영은 마침내 절구 한 수를 읊었다.왕자진이 피리를 부니 달도 내려와 들으려는데,바다처럼 푸른 하늘엔 이슬이 서늘하네.때마침 날아가는 푸른 난새를 함께 타고서도,안개와 노을이 가득해 봉도 가는 길 찾을 수 없네.최척은 애초에 자기 아내가 이리 시를 잘 읊는 줄 모르고 있던터라 놀라 감탄하였다.[중략 줄거리] 전란으로 가족과 이별한 최척은 명나라 배를 타고 안남에 이르러 처량한 마음에 피리를 불었다.최척은 동방이 밝아 오자, 강둑을 내려가 일본인 배에 이르러조선말로 물었다.“어젯밤 시를 읊던 사람은 조선 사람 아닙니까? 나도 조선 사람이어서 한번 만나 보았으면 합니다. 멀리 다른 나라를떠도는 사람이 비슷하게 생긴 고국 사람을 만나는 것이 어찌 그저 기쁘기만 한 일이겠습니까?”옥영도 생각하기를 어젯밤 들은 피리 소리가 조선의 곡조인데다, 평소 익히 들었던 것과 너무나 흡사했다. 그래서 남편 생각에감회가 일어 절로 시를 읊게 되었던 것이다. 옥영은 자기를 찾는 사람의 목소리를 듣고는 황망히 뛰쳐나와 최척을 보았다. 둘은 서로 마주하고 놀라 소리를 지르며 끌어안고 백사장을 뒹굴었다. 목이 메고 기가 막혀 마음을 안정할 수 없었으며, 말도 할 수 없었다. 눈에서는 눈물이 다하자 피가 흘러내려 서로를 볼 수도 없을 지경이었다. 양국의 뱃사람들이 저잣거리처럼 모여들어 구경했는데, 처음에는 친척이나 잘 아는 친구인 줄로만 알았다. 뒤에 그들이 부부 사이라는 것을 알고 서로 돌아보며 소리쳐 말했다.“이상하고 기이한 일이로다! 이것은 하늘의 뜻이요, 사람이 이룰 수 있는 일이 아니로다. 이런 일은 옛날에도 들어 보지 못하였다.”최척은 옥영에게 그간의 소식을 물었다.“산속에서 붙들려 강가로 끌려갔다는데, 그때 아버지와 장모님은 어찌 되었소?”옥영이 말했다.“날이 어두워진 뒤 배에 오른 데다 정신이 없어 서로 잃어버렸으니, 제가 두 분의 안위를 어떻게 알겠습니까?”두 사람이 손을 붙들고 통곡하자, 옆에서 지켜보던 사람들도 슬퍼하며 눈물을 닦지 않는 이가 없었다.- 조위한, 최척전 -', 'type': 1, 'problems': [{'question': '윗글에 대한 설명으로 가장 적절한 것은?', 'choices': ['시를 삽입하여 인물 간의 갈등 양상이 구체화되는 상황을 드러내고 있다.', '인물의 행위가 연속적으로 나열된 장면을 통해 신분의 변화 과정을 드러내고 있다.', '주변 인물이 알고 있는 사례를 근거로 주요 인물에 대해 상반된평가를 내리게 하고 있다.', '감각적인 배경 묘사를 통해 인물의 행동이 전개되는 상황의 낭만적 분위기를 부각하고 있다.', '인물 간 대화가 오가는 장면을 보여 주어 이전 사건에 따른 다른 인물들의 현재 행선지를 드러내고 있다.'], 'answer': 4, 'score': 2}, {'question': '윗글의 인물에 대한 이해로 적절하지 않은 것은?', 'choices': ['‘뱃사람들’은 최척과 옥영의 관계가 자신들이 생각하던 것과 달라 놀라워했다.', '‘최척’은 강둑을 내려가 자신을 ‘다른 나라를 떠도는 사람’이라말하며 자신의 처지와 심정을 드러냈다.', '‘최척’은 옥영의 시에 대한 재능을 결혼 전에 알고 있었지만, 옥영이 시를 읊기 전까지 이를 모른 척했다.', '‘옥영’은 가정의 구성원들을 정성스러운 마음으로 대했고, 옥영이 시집온 후 최척의 집안은 점차 부유해졌다.', '‘친척들’은 최척의 결혼을 경사로 받아들였고, ‘이웃 사람들’은 옥영의 행실을 칭찬했다.'], 'answer': 3, 'score': 2}, {'question': '㉠～㉤에 대한 이해로 가장 적절한 것은?', 'choices': ['㉠은 인물의 심리적 갈등이 발생하는, ㉢은 ㉠에서 발생한 갈등이 심화되는 시간의 표지이다.', '㉢과 ㉤은 모두 과거의 행위를 통해 인물의 성격이 변화됨을 드러내는 시간의 표지이다.', '㉣은 인물의 행위가 반복적으로 일어나는, ㉤은 ㉣ 중 한 시점을 특정하는 시간의 표지이다.', '㉡은 ㉠에서부터 이어진 행위를 알려 주는, ㉤은 그 행위가 완결된 순간을 지시하는 시간의 표지이다.', '㉡과 ㉢은 인물의 소망이 실현되어 가는 과정에 포함되는, ㉤은 인물의 소망이 좌절된 시간의 표지이다.'], 'answer': 3, 'score': 2}, {'question': '<보기>를 바탕으로 윗글을 감상한 내용으로 적절하지 않은것은?', 'question_plus': '<보 기>최척전 에는 하나의 문제 상황이 해결되면 또 다른 문제가확인되는 서사 구조가 나타나고 있다. 이 과정에서 도움을 주는 신이한 존재를 나타나게 하거나, 예언의 실현을 보여 주는 특이한 증거를 활용하거나, 문제 해결의 계기가 되는 소재를 제시하거나, 공간적 배경을 확장하여 다양한 국적의 사람들을 등장시키는 등의 서사적 장치들이 확인된다. 이러한서사 구조와 다양한 서사적 장치는 독자가 이야기에 흥미를 가지고 그것을 자연스럽게 수용하는 데 기여한다', 'choices': ['옥영의 꿈에 나타난 ‘만복사의 부처’는, 옥영이 겪고 있는 현실적인 문제를 해결하는 데 도움을 주는 신이한 존재로서 역할을 한다고 볼 수 있겠군.', '몽석의 몸에 나타난 ‘붉은 점’은, ‘사내아이’의 출생과 관련한 예언이 실제로 이루어졌음을 확인할 수 있는 특이한 증거로 활용된다고 볼 수 있겠군.', '최척이 ‘일본인 배에 이르러 조선말로 물’어보는 것과 ‘고국 사람을 만나’려 하는 것은, 서사 전개 과정에서 공간적 배경을 조선뿐 아니라 다른 나라로도 확장한 것과 관련이 있겠군.', '옥영이 들은 ‘피리 소리’는, 옥영이 최척을 떠올리게 하여 이별의 상황을 해결하는 계기가 되는 소재로 작용하고 있다고 볼 수 있겠군.', '최척과 옥영이 ‘소리를 지르며 끌어안’는 것은 문제의 해결에 따른 기쁨과, ‘눈물이 다하자 피가 흘러내’리는 것은 또 다른 문제 확인에 따른 인물의 불안감과 관련이 있겠군.'], 'answer': 5, 'score': 3}]}]\n",
            "Number of problems loaded: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측 테스트"
      ],
      "metadata": {
        "id": "tFpnmNJwdNdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT-4 예측 실행 테스트\n",
        "test_problem = {\n",
        "    \"question\": \"다음 중 가장 큰 숫자는?\",\n",
        "    \"choices\": [\"1\", \"2\", \"3\", \"4\"]\n",
        "}\n",
        "print(f\"Test Prediction: {prediction(test_problem)}\")  # 4 출력 예상\n",
        "\n",
        "# 전체 문제 예측 실행\n",
        "print(\"Running predictions...\")\n",
        "predictions = []\n",
        "for problem in problems:\n",
        "    pred = prediction(problem)\n",
        "    predictions.append(pred)\n",
        "\n",
        "# 점수 계산\n",
        "print(\"Calculating score...\")\n",
        "score = calculate_score(predictions, answers)\n",
        "\n",
        "print(f\"Final Score: {score}/100\")\n",
        "if score >= 80:\n",
        "    print(\"✅ 80점 이상 조건 달성\")\n",
        "else:\n",
        "    print(\"❌ 80점 미만\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRxdsZzMdOdt",
        "outputId": "c4ed33fa-9dcf-4eee-b97f-d7a9f85f9c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Test Prediction: None\n",
            "Running predictions...\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "API 호출 오류: \n",
            "\n",
            "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
            "\n",
            "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
            "\n",
            "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
            "\n",
            "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
            "\n",
            "Calculating score...\n",
            "Final Score: 0.0/100\n",
            "❌ 80점 미만\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rate limits\n",
        "\n",
        "\n",
        "Copy page\n",
        "Understand API rate limits and restrictions.\n",
        "Rate limits are restrictions that our API imposes on the number of times a user or client can access our services within a specified period of time.\n",
        "\n",
        "위 오류가 계속 나서 실행은 못했습니다.\n"
      ],
      "metadata": {
        "id": "wPFM3Q8UqBmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Hugging Face 모델 로드\n",
        "model_name = \"gpt2\"  # GPT-2 모델 이름\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# JSON 데이터 로드 함수\n",
        "def load_kice_data(filepath):\n",
        "    \"\"\"\n",
        "    JSON 파일에서 데이터를 로드합니다.\n",
        "    \"\"\"\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        return json.load(file)\n",
        "\n",
        "# 문제 예측 함수\n",
        "def prediction_with_huggingface(problem):\n",
        "    \"\"\"\n",
        "    Hugging Face 모델을 사용하여 문제를 해결합니다.\n",
        "    \"\"\"\n",
        "    # 문제 구성\n",
        "    prompt = f\"다음은 수능 국어 문제입니다:\\n\\n질문: {problem['question']}\\n\\n선택지:\\n\"\n",
        "    for idx, choice in enumerate(problem['choices'], start=1):\n",
        "        prompt += f\"{idx}. {choice}\\n\"\n",
        "    prompt += \"\\n정답은\"\n",
        "\n",
        "    # 모델의 최대 입력 길이를 초과하지 않도록 자르기\n",
        "    max_input_length = model.config.n_positions - 50  # 최대 길이 - 예측에 필요한 공간 확보\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
        "\n",
        "    # 모델 예측\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_new_tokens=50,  # 모델이 생성할 최대 토큰 수\n",
        "        num_return_sequences=1,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tokenizer.eos_token_id  # 패딩 토큰 설정\n",
        "    )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # 정답 번호 추출\n",
        "    try:\n",
        "        for idx, choice in enumerate(problem['choices'], start=1):\n",
        "            if str(idx) in response:\n",
        "                return idx\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing response: {e}\")\n",
        "    return None\n",
        "\n",
        "# 점수 계산 함수\n",
        "def calculate_score(predictions, answers):\n",
        "    \"\"\"\n",
        "    모델 예측 결과와 실제 정답을 비교하여 점수를 계산합니다.\n",
        "    \"\"\"\n",
        "    correct = sum([1 for pred, answer in zip(predictions, answers) if pred == answer])\n",
        "    total = len(answers)\n",
        "    return (correct / total) * 100\n",
        "\n",
        "# 데이터 로드\n",
        "print(\"Loading KICE data...\")\n",
        "!git clone https://github.com/NomaDamas/KICE_slayer_AI_Korean.git || echo \"Repository already cloned.\"\n",
        "\n",
        "data = load_kice_data(\"KICE_slayer_AI_Korean/data/2023_11_KICE.json\")\n",
        "print(\"KICE data loaded successfully.\")\n",
        "\n",
        "# 문제와 정답 리스트 생성\n",
        "problems = []\n",
        "answers = []\n",
        "\n",
        "for item in data:\n",
        "    for problem in item[\"problems\"]:\n",
        "        problems.append(problem)\n",
        "        answers.append(problem[\"answer\"])\n",
        "\n",
        "print(f\"Number of problems loaded: {len(problems)}\")\n",
        "\n",
        "# GPT-2 예측 실행 테스트\n",
        "print(\"Test Prediction...\")\n",
        "test_problem = {\n",
        "    \"question\": \"다음 중 가장 큰 숫자는?\",\n",
        "    \"choices\": [\"1\", \"2\", \"3\", \"4\"]\n",
        "}\n",
        "print(f\"Test Prediction: {prediction_with_huggingface(test_problem)}\")  # 4 출력 예상\n",
        "\n",
        "# 전체 문제 예측 실행\n",
        "print(\"Running predictions...\")\n",
        "predictions = []\n",
        "for problem in problems:\n",
        "    pred = prediction_with_huggingface(problem)\n",
        "    predictions.append(pred)\n",
        "\n",
        "# 점수 계산\n",
        "print(\"Calculating score...\")\n",
        "score = calculate_score(predictions, answers)\n",
        "\n",
        "print(f\"Final Score: {score}/100\")\n",
        "if score >= 80:\n",
        "    print(\"✅ 80점 이상 조건 달성\")\n",
        "else:\n",
        "    print(\"❌ 80점 미만\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_-boNTSqHRX",
        "outputId": "0df8768a-7663-4747-c8fe-7211bda4c158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading KICE data...\n",
            "fatal: destination path 'KICE_slayer_AI_Korean' already exists and is not an empty directory.\n",
            "Repository already cloned.\n",
            "KICE data loaded successfully.\n",
            "Number of problems loaded: 45\n",
            "Test Prediction...\n",
            "Test Prediction: 1\n",
            "Running predictions...\n",
            "Calculating score...\n",
            "Final Score: 17.77777777777778/100\n",
            "❌ 80점 미만\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "open api 가 안써져서 gpt2 로 실행해 봤는데, 일단 정답률이 굉장히 낮습니다."
      ],
      "metadata": {
        "id": "iAeqPt9MtN5q"
      }
    }
  ]
}
